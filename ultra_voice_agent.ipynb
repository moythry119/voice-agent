{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c541773-acf9-46c7-8f9a-310a08de9239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 16:37:03) [MSC v.1929 64 bit (AMD64)]\n",
      "OS: Windows-11-10.0.26100-SP0\n"
     ]
    }
   ],
   "source": [
    "import sys, platform, time, os\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OS:\", platform.platform())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad319c94-e163-4bcc-82f0-42ed1463b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet sounddevice soundfile numpy SpeechRecognition pyttsx3 google-generativeai\n",
    "# Optional (better STT):\n",
    "# !pip install --quiet openai-whisper torch --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0d38841a-a284-486e-ba08-21a59a9f47ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording… (start speaking clearly)\n",
      "Saved: input.wav\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd, soundfile as sf, numpy as np\n",
    "\n",
    "SAMPLERATE = 16000\n",
    "DURATION   = 6\n",
    "WAV_FILE   = \"input.wav\"\n",
    "\n",
    "print(\"Recording… (start speaking)\")\n",
    "audio = sd.rec(int(DURATION * SAMPLERATE), samplerate=SAMPLERATE, channels=1, dtype='float32')\n",
    "sd.wait()\n",
    "audio = np.clip(audio * 1.8, -1.0, 1.0)  # gain\n",
    "sf.write(WAV_FILE, audio, SAMPLERATE)\n",
    "print(\"Saved:\", WAV_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "77edd62a-12eb-4386-b3d5-4cd7805fef38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said: I am Soumya email Soumya at Gmail.com\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "with sr.AudioFile(WAV_FILE) as source:\n",
    "    recognizer.adjust_for_ambient_noise(source, duration=0.2)\n",
    "    audio_data = recognizer.record(source)\n",
    "\n",
    "try:\n",
    "    user_text = recognizer.recognize_google(audio_data, language=\"en-US\")\n",
    "    print(\"You said:\", user_text)\n",
    "except sr.UnknownValueError:\n",
    "    user_text = \"\"\n",
    "    print(\"Couldn’t understand the audio.\")\n",
    "except sr.RequestError as e:\n",
    "    user_text = \"\"\n",
    "    print(\"Google SR request error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a3e524a4-ca7d-4d90-a47d-1fef5695d828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No Gemini API key found. Switching to mock.\n",
      "AI reply: (mock) You said: I am Soumya email Soumya at Gmail.com\n",
      "Model latency: 150.2 ms\n"
     ]
    }
   ],
   "source": [
    " import google.generativeai as genai\n",
    "import time\n",
    "\n",
    "USE_GEMINI = True  # False for mock reply, use true when use gemini key\n",
    "GEMINI_MODEL = \"models/gemini-1.5-pro-latest\"\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"\", \"\")   \n",
    "if USE_GEMINI and not GEMINI_API_KEY:\n",
    "    print(\"⚠️ No Gemini API key found. Switching to mock.\")\n",
    "    USE_GEMINI = False\n",
    "else:\n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "def ai_reply_from_gemini(text):\n",
    "    prompt = f\"You are a concise voice agent. User said: {text}\"\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        model = genai.GenerativeModel(GEMINI_MODEL)\n",
    "        resp = model.generate_content(prompt)\n",
    "        reply = getattr(resp, \"text\", str(resp))\n",
    "    except Exception as e:\n",
    "        reply = f\"(fallback) I heard: {text}\"\n",
    "        print(\"Gemini error:\", e)\n",
    "    latency = (time.time() - t0) * 1000\n",
    "    return reply, latency\n",
    "\n",
    "def ai_reply_mock(text):\n",
    "    t0 = time.time()\n",
    "    time.sleep(0.15)\n",
    "    latency = (time.time() - t0) * 1000\n",
    "    return f\"(mock) You said: {text}\", latency\n",
    "\n",
    "if user_text.strip():\n",
    "    if USE_GEMINI:\n",
    "        ai_text, model_latency_ms = ai_reply_from_gemini(user_text)\n",
    "    else:\n",
    "        ai_text, model_latency_ms = ai_reply_mock(user_text)\n",
    "    print(\"AI reply:\", ai_text)\n",
    "    print(f\"Model latency: {model_latency_ms:.1f} ms\")\n",
    "else:\n",
    "    ai_text, model_latency_ms = \"(no input)\", 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3fa88303-c5a6-49a7-a684-332a70a4e818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaking: (mock) You said: I am Soumya email Soumya at Gmail.com\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 185)   \n",
    "print(\"Speaking:\", ai_text)\n",
    "engine.say(ai_text)\n",
    "engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ef1d0d0e-cdc2-42ab-abfc-dcd27e583e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form after extraction:\n",
      "{\n",
      "  \"name\": \"Soumya\",\n",
      "  \"email\": \"soumya@gmail.com\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re, json\n",
    "\n",
    "form = {\"name\": \"\", \"email\": \"\"}\n",
    "\n",
    "txt = (user_text or \"\").lower()\n",
    "\n",
    "# Name extraction - stop when reaching 'my email' or 'email'\n",
    "m = re.search(r\"(?:my name is|i am)\\s+([a-zA-Z]+)\", txt)\n",
    "if m:\n",
    "    form[\"name\"] = m.group(1).title()\n",
    "\n",
    "# Email extraction\n",
    "m = re.search(r\"([a-z0-9._%+-]+@[a-z0-9.-]+\\.[a-z]{2,})\", txt)\n",
    "if m:\n",
    "    form[\"email\"] = m.group(1)\n",
    "else:\n",
    "    m = re.search(r\"(?:my email is|email)\\s+([a-z0-9._%+-]+)\\s*(?:at)?\\s*(gmail|yahoo|outlook)\", txt)\n",
    "    if m:\n",
    "        form[\"email\"] = f\"{m.group(1)}@{m.group(2)}.com\"\n",
    "\n",
    "print(\"Form after extraction:\")\n",
    "print(json.dumps(form, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "495071df-c4f2-4ef0-8e6a-8b9351c3b3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 151.0 ms | TTS: 181.1 ms | Total: 332.3 ms\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "_ = ai_reply_from_gemini(user_text)[0] if USE_GEMINI else ai_reply_mock(user_text)[0]\n",
    "t_model_end = time.time()\n",
    "tts_start = time.time()\n",
    "engine.say(ai_text)\n",
    "engine.runAndWait()\n",
    "t_end = time.time()\n",
    "\n",
    "model_ms  = (t_model_end - t_start) * 1000\n",
    "tts_ms    = (t_end - tts_start) * 1000\n",
    "total_ms  = (t_end - t_start) * 1000\n",
    "\n",
    "print(f\"Model: {model_ms:.1f} ms | TTS: {tts_ms:.1f} ms | Total: {total_ms:.1f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8510cdba-c332-4843-8164-0cd4b37da3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Performance Report (Notebook)\n",
      "\n",
      "- ASR: SpeechRecognition\n",
      "- LLM: Mock reply\n",
      "- TTS: pyttsx3 (offline)\n",
      "- Latencies:\n",
      "  - Model: ~151 ms\n",
      "  - TTS: ~181 ms\n",
      "  - Total: ~332 ms\n",
      "\n",
      "## Why not <500 ms?\n",
      "- This is single-shot. Streaming STT/LLM/TTS would be needed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = f\"\"\"\n",
    "# Performance Report (Notebook)\n",
    "\n",
    "- ASR: {'SpeechRecognition' if 'speech_recognition' in sys.modules else 'Whisper'}\n",
    "- LLM: {'Gemini ' + GEMINI_MODEL if USE_GEMINI else 'Mock reply'}\n",
    "- TTS: pyttsx3 (offline)\n",
    "- Latencies:\n",
    "  - Model: ~{model_ms:.0f} ms\n",
    "  - TTS: ~{tts_ms:.0f} ms\n",
    "  - Total: ~{total_ms:.0f} ms\n",
    "\n",
    "## Why not <500 ms?\n",
    "- This is single-shot. Streaming STT/LLM/TTS would be needed.\n",
    "\"\"\"\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f190a55b-75e8-41d1-b8be-50ab9a61bb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
